{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7d148925e1512e97d54d10ab5b5f5d2debe6de24"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "b35c225ad459730c3dddd71983a356aa216a01a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Smile/anaconda/lib/python3.6/site-packages/scipy/__init__.py:115: UserWarning: Numpy 1.13.3 or above is required for this version of scipy (detected version 1.12.1)\n",
      "  UserWarning)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xb but this version of numpy is 0xa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xb but this version of numpy is 0xa"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-94e410433f4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmplot3d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAxes3D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Smile/anaconda/lib/python3.6/site-packages/scipy/sparse/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcsr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcsc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Smile/anaconda/lib/python3.6/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n\u001b[0m\u001b[1;32m     14\u001b[0m                            get_csr_submatrix)\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msputils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mupcast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_index_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "from __future__ import (absolute_import, division, print_function, unicode_literals)\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import re\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from surprise import Reader, Dataset, SVD, evaluate\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import six\n",
    "from tabulate import tabulate\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import KFold\n",
    "from surprise import NormalPredictor\n",
    "from surprise import BaselineOnly\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNBaseline\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (6, 4)\n",
    "plt.style.use('ggplot')\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "85afa5ae7d85793c5215912fddb1c22e9473d092",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anime = pd.read_csv('../anime.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "784ace04e2dacbcdac499fb5c9305a5f5a933b86",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "28b75ceb5cd4936bb8585825e89fdd3c16bcd00e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(anime.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e55cbb28a50ceaa8878f203a5fa63b930279ffbb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user = pd.read_csv('../rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f3f30edfe9b7ec4529270d9e534a900a99df8aec",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0fab9d0f7191758fa12cd527aabeb781f5aaf569",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(user.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop the data that rating is -1\n",
    "user_filtered = user[user.rating!=(-1)]\n",
    "user_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop the user that user_frequency < 130\n",
    "user_filtered = user_filtered.groupby('user_id').filter(lambda x : (x['user_id'].count()>=130).any())\n",
    "user_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create df of anime < 50000 members\n",
    "title_ge50000 = anime[anime.members>=50000]\n",
    "title_ge50000.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_ge50000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_ge50000.anime_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_filtered['user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop any anime < 50000 members\n",
    "user_filtered = userSVD[userSVD['anime_id'].isin(title_ge50000.anime_id)] \n",
    "user_filtered.head()\n",
    "\n",
    "#drop any user's rating on a droped anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop the data that index >10000\n",
    "user_filtered = user_filtered.reset_index()\n",
    "user_filtered = user_filtered.drop(columns=['index'])\n",
    "user_filtered.head()\n",
    "user_filtered.to_csv('user_filtered.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_title = anime.drop(['genre','type','episodes','rating','members'], axis=1)\n",
    "df_title.set_index('anime_id', inplace = True)\n",
    "print (df_title.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adjust the scale for the function in Surprise\n",
    "reader = Reader(rating_scale=(0, 10))\n",
    "\n",
    "# Format the dataset to correspond to required format \n",
    "# colume: user id, item id and ratings.\n",
    "data = Dataset.load_from_df(user_filtered[['user_id', 'anime_id', 'rating']], reader)\n",
    "\n",
    "#this user likes in the past\n",
    "df_1 = user_filtered[(user_filtered['user_id'] == 1) & (user_filtered['rating'] == 10)]\n",
    "df_1 = df_1.set_index('anime_id')\n",
    "df_1 = df_1.join(anime.name)['name']\n",
    "print(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prediction what this user will like to watch\n",
    "\n",
    "#drop all anime that this user has watched\n",
    "user_1 = df_title.copy()\n",
    "user_1 = user_1.reset_index()\n",
    "user_1 = user_1[~user_1['anime_id'].isin(df_title)]\n",
    "\n",
    "# getting full dataset\n",
    "##data = Dataset.load_from_df(user[['user_id', 'anime_id', 'rating']], reader)\n",
    "\n",
    "trainset = data.build_full_trainset()\n",
    "svd = SVD()\n",
    "svd.train(trainset)\n",
    "\n",
    "user_1['Estimate_Score'] = user_1['anime_id'].apply(lambda x: svd.predict(1, x).est)\n",
    "\n",
    "user_1 = user_1.drop('anime_id', axis = 1)\n",
    "\n",
    "user_1 = user_1.sort_values('Estimate_Score', ascending=False)\n",
    "print(user_1.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The algorithms to cross-validate\n",
    "classes = (SVD, NMF, SlopeOne, KNNBasic, KNNWithMeans, KNNBaseline, CoClustering, BaselineOnly, NormalPredictor)\n",
    "\n",
    "# ugly dict to map algo names and datasets to their markdown links in the table\n",
    "stable = 'http://surprise.readthedocs.io/en/stable/'\n",
    "LINK = {'SVD': '[{}]({})'.format('SVD',\n",
    "                                 stable +\n",
    "                                 'matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD'),\n",
    "        'NMF': '[{}]({})'.format('NMF',\n",
    "                                stable +\n",
    "                                'matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.NMF'),\n",
    "        'SlopeOne': '[{}]({})'.format('Slope One',\n",
    "                                     stable +\n",
    "                                     'slope_one.html#surprise.prediction_algorithms.slope_one.SlopeOne'),\n",
    "        'KNNBasic': '[{}]({})'.format('k-NN',\n",
    "                                     stable +\n",
    "                                     'knn_inspired.html#surprise.prediction_algorithms.knns.KNNBasic'),\n",
    "        'KNNWithMeans': '[{}]({})'.format('Centered k-NN',\n",
    "                                          stable +\n",
    "                                          'knn_inspired.html#surprise.prediction_algorithms.knns.KNNWithMeans'),\n",
    "        'KNNBaseline': '[{}]({})'.format('k-NN Baseline',\n",
    "                                         stable +\n",
    "                                         'knn_inspired.html#surprise.prediction_algorithms.knns.KNNBaseline'),\n",
    "        'CoClustering': '[{}]({})'.format('Co-Clustering',\n",
    "                                          stable +\n",
    "                                          'co_clustering.html#surprise.prediction_algorithms.co_clustering.CoClustering'),\n",
    "        'BaselineOnly': '[{}]({})'.format('Baseline',\n",
    "                                          stable +\n",
    "                                          'basic_algorithms.html#surprise.prediction_algorithms.baseline_only.BaselineOnly'),\n",
    "        'NormalPredictor': '[{}]({})'.format('Random',\n",
    "                                             stable +\n",
    "                                             'basic_algorithms.html#surprise.prediction_algorithms.random_pred.NormalPredictor'),\n",
    "        }\n",
    "\n",
    "\n",
    "# set RNG\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "kf = KFold(random_state=0)  # folds will be the same for all algorithms.\n",
    "\n",
    "table = []\n",
    "for klass in classes:\n",
    "    start = time.time()\n",
    "    out = cross_validate(klass(), data, ['rmse', 'mae'], kf)\n",
    "    cv_time = str(datetime.timedelta(seconds=int(time.time() - start)))\n",
    "    link = LINK[klass.__name__]\n",
    "    mean_rmse = '{:.3f}'.format(np.mean(out['test_rmse']))\n",
    "    mean_mae = '{:.3f}'.format(np.mean(out['test_mae']))\n",
    "\n",
    "    new_line = [link, mean_rmse, mean_mae, cv_time]\n",
    "    print(tabulate([new_line], tablefmt=\"pipe\"))  # print current algo perf\n",
    "    table.append(new_line)\n",
    "\n",
    "header = ['data',\n",
    "          'RMSE',\n",
    "          'MAE',\n",
    "          'Time'\n",
    "          ]\n",
    "print(tabulate(table, header, tablefmt=\"pipe\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
